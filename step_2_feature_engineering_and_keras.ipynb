{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train using Keras and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Dataset from Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19579, 158)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename_combined = './datasets/train_svd_meta_features.csv'\n",
    "X_combined = pd.read_csv(filename_combined, index_col=0)\n",
    "X_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_words</th>\n",
       "      <th>num_unique_words</th>\n",
       "      <th>num_chars</th>\n",
       "      <th>num_stopwords</th>\n",
       "      <th>num_punctuations</th>\n",
       "      <th>num_words_upper</th>\n",
       "      <th>num_words_title</th>\n",
       "      <th>mean_word_len</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>...</th>\n",
       "      <th>140</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41</td>\n",
       "      <td>35</td>\n",
       "      <td>231</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4.658537</td>\n",
       "      <td>0.025145</td>\n",
       "      <td>-0.011614</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013187</td>\n",
       "      <td>0.005173</td>\n",
       "      <td>0.019562</td>\n",
       "      <td>-0.006568</td>\n",
       "      <td>0.010394</td>\n",
       "      <td>0.002122</td>\n",
       "      <td>0.012697</td>\n",
       "      <td>-0.011682</td>\n",
       "      <td>-0.001399</td>\n",
       "      <td>0.007098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>71</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.142857</td>\n",
       "      <td>0.009298</td>\n",
       "      <td>-0.003849</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002916</td>\n",
       "      <td>0.021468</td>\n",
       "      <td>-0.001444</td>\n",
       "      <td>0.002863</td>\n",
       "      <td>0.021814</td>\n",
       "      <td>-0.013015</td>\n",
       "      <td>0.004528</td>\n",
       "      <td>-0.019859</td>\n",
       "      <td>-0.013882</td>\n",
       "      <td>-0.013202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36</td>\n",
       "      <td>32</td>\n",
       "      <td>200</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.583333</td>\n",
       "      <td>0.029143</td>\n",
       "      <td>-0.014501</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001663</td>\n",
       "      <td>-0.002504</td>\n",
       "      <td>-0.016635</td>\n",
       "      <td>0.000264</td>\n",
       "      <td>-0.011337</td>\n",
       "      <td>-0.001371</td>\n",
       "      <td>0.014661</td>\n",
       "      <td>-0.011137</td>\n",
       "      <td>0.004494</td>\n",
       "      <td>-0.005027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34</td>\n",
       "      <td>32</td>\n",
       "      <td>206</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5.088235</td>\n",
       "      <td>0.029090</td>\n",
       "      <td>-0.013946</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013244</td>\n",
       "      <td>-0.007751</td>\n",
       "      <td>-0.008763</td>\n",
       "      <td>0.006229</td>\n",
       "      <td>-0.004968</td>\n",
       "      <td>-0.011337</td>\n",
       "      <td>-0.001989</td>\n",
       "      <td>-0.011501</td>\n",
       "      <td>0.007581</td>\n",
       "      <td>0.011213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>25</td>\n",
       "      <td>174</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5.481481</td>\n",
       "      <td>0.012538</td>\n",
       "      <td>-0.007765</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005170</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.003195</td>\n",
       "      <td>0.010974</td>\n",
       "      <td>-0.003369</td>\n",
       "      <td>-0.008774</td>\n",
       "      <td>-0.000578</td>\n",
       "      <td>0.001529</td>\n",
       "      <td>-0.000351</td>\n",
       "      <td>0.002611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 158 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_words  num_unique_words  num_chars  num_stopwords  num_punctuations  \\\n",
       "0         41                35        231             19                 7   \n",
       "1         14                14         71              8                 1   \n",
       "2         36                32        200             16                 5   \n",
       "3         34                32        206             13                 4   \n",
       "4         27                25        174             11                 4   \n",
       "\n",
       "   num_words_upper  num_words_title  mean_word_len         0         1  ...  \\\n",
       "0                2                3       4.658537  0.025145 -0.011614  ...   \n",
       "1                0                1       4.142857  0.009298 -0.003849  ...   \n",
       "2                0                1       4.583333  0.029143 -0.014501  ...   \n",
       "3                0                4       5.088235  0.029090 -0.013946  ...   \n",
       "4                0                2       5.481481  0.012538 -0.007765  ...   \n",
       "\n",
       "        140       141       142       143       144       145       146  \\\n",
       "0  0.013187  0.005173  0.019562 -0.006568  0.010394  0.002122  0.012697   \n",
       "1 -0.002916  0.021468 -0.001444  0.002863  0.021814 -0.013015  0.004528   \n",
       "2  0.001663 -0.002504 -0.016635  0.000264 -0.011337 -0.001371  0.014661   \n",
       "3 -0.013244 -0.007751 -0.008763  0.006229 -0.004968 -0.011337 -0.001989   \n",
       "4 -0.005170  0.000144  0.003195  0.010974 -0.003369 -0.008774 -0.000578   \n",
       "\n",
       "        147       148       149  \n",
       "0 -0.011682 -0.001399  0.007098  \n",
       "1 -0.019859 -0.013882 -0.013202  \n",
       "2 -0.011137  0.004494 -0.005027  \n",
       "3 -0.011501  0.007581  0.011213  \n",
       "4  0.001529 -0.000351  0.002611  \n",
       "\n",
       "[5 rows x 158 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_dataset_org = './datasets/train.csv'\n",
    "data_df = pd.read_csv(filename_dataset_org)\n",
    "y_train = data_df['author'].map({'EAP':0, 'HPL':1, 'MWS':2})\n",
    "\n",
    "del data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19579,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 2, 1])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_categorical = keras.utils.to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_14 (InputLayer)        (None, 158)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 3)                 477       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 477\n",
      "Trainable params: 477\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_model(input_dim, fc1_dim, output_dim=3, lr=1e-3):\n",
    "    inputs = keras.layers.Input(input_dim[1:])\n",
    "    \n",
    "    x_fc = keras.layers.Dense(output_dim)(inputs)\n",
    "    outputs = keras.layers.Activation('softmax')(x_fc)\n",
    "    \n",
    "    model = keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "    optimizer = keras.optimizers.Adam(lr=lr)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                 optimizer=optimizer,\n",
    "                 metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "model = create_model(input_dim=X_combined.shape, fc1_dim=64)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "19579/19579 [==============================] - 0s 15us/step - loss: 2.3128 - acc: 0.3493\n",
      "Epoch 2/100\n",
      "19579/19579 [==============================] - 0s 6us/step - loss: 1.2335 - acc: 0.3441\n",
      "Epoch 3/100\n",
      "19579/19579 [==============================] - 0s 6us/step - loss: 1.1732 - acc: 0.3586\n",
      "Epoch 4/100\n",
      "19579/19579 [==============================] - 0s 6us/step - loss: 1.1284 - acc: 0.3823\n",
      "Epoch 5/100\n",
      "19579/19579 [==============================] - 0s 6us/step - loss: 1.0960 - acc: 0.4092\n",
      "Epoch 6/100\n",
      "19579/19579 [==============================] - 0s 6us/step - loss: 1.0744 - acc: 0.4388\n",
      "Epoch 7/100\n",
      "19579/19579 [==============================] - 0s 6us/step - loss: 1.0563 - acc: 0.4631\n",
      "Epoch 8/100\n",
      "19579/19579 [==============================] - 0s 6us/step - loss: 1.0407 - acc: 0.4781\n",
      "Epoch 9/100\n",
      "19579/19579 [==============================] - 0s 6us/step - loss: 1.0289 - acc: 0.4917\n",
      "Epoch 10/100\n",
      "19579/19579 [==============================] - 0s 6us/step - loss: 1.0192 - acc: 0.5041\n",
      "Epoch 11/100\n",
      "19579/19579 [==============================] - 0s 6us/step - loss: 1.0107 - acc: 0.5051\n",
      "Epoch 12/100\n",
      "19579/19579 [==============================] - 0s 6us/step - loss: 1.0011 - acc: 0.5155\n",
      "Epoch 13/100\n",
      "19579/19579 [==============================] - 0s 6us/step - loss: 0.9943 - acc: 0.5206\n",
      "Epoch 14/100\n",
      "19579/19579 [==============================] - 0s 6us/step - loss: 0.9869 - acc: 0.5262\n",
      "Epoch 15/100\n",
      "19579/19579 [==============================] - 0s 6us/step - loss: 0.9810 - acc: 0.5353\n",
      "Epoch 16/100\n",
      "19579/19579 [==============================] - 0s 6us/step - loss: 0.9756 - acc: 0.5381\n",
      "Epoch 17/100\n",
      "19579/19579 [==============================] - 0s 6us/step - loss: 0.9700 - acc: 0.5452\n",
      "Epoch 18/100\n",
      "19579/19579 [==============================] - 0s 6us/step - loss: 0.9624 - acc: 0.5523\n",
      "Epoch 19/100\n",
      "19579/19579 [==============================] - 0s 6us/step - loss: 0.9575 - acc: 0.5568\n",
      "Epoch 20/100\n",
      "19579/19579 [==============================] - 0s 6us/step - loss: 0.9532 - acc: 0.5610\n",
      "Epoch 21/100\n",
      "19579/19579 [==============================] - 0s 6us/step - loss: 0.9475 - acc: 0.5667\n",
      "Epoch 22/100\n",
      "19579/19579 [==============================] - 0s 6us/step - loss: 0.9429 - acc: 0.5735\n",
      "Epoch 23/100\n",
      "19579/19579 [==============================] - 0s 6us/step - loss: 0.9405 - acc: 0.5743\n",
      "Epoch 24/100\n",
      "19579/19579 [==============================] - 0s 6us/step - loss: 0.9355 - acc: 0.5770\n",
      "Epoch 25/100\n",
      "19579/19579 [==============================] - 0s 6us/step - loss: 0.9316 - acc: 0.5782\n",
      "Epoch 26/100\n",
      "19579/19579 [==============================] - 0s 6us/step - loss: 0.9278 - acc: 0.5842\n",
      "Epoch 27/100\n",
      "19579/19579 [==============================] - 0s 6us/step - loss: 0.9251 - acc: 0.5851\n",
      "Epoch 28/100\n",
      "19579/19579 [==============================] - 0s 6us/step - loss: 0.9201 - acc: 0.5911\n",
      "Epoch 29/100\n",
      "19579/19579 [==============================] - 0s 6us/step - loss: 0.9158 - acc: 0.5942\n",
      "Epoch 30/100\n",
      "19579/19579 [==============================] - 0s 6us/step - loss: 0.9131 - acc: 0.5982\n",
      "Epoch 31/100\n",
      "19579/19579 [==============================] - 0s 6us/step - loss: 0.9120 - acc: 0.5990\n",
      "Epoch 32/100\n",
      "19579/19579 [==============================] - 0s 6us/step - loss: 0.9082 - acc: 0.6025\n",
      "Epoch 33/100\n",
      "19579/19579 [==============================] - 0s 6us/step - loss: 0.9041 - acc: 0.6047\n",
      "Epoch 34/100\n",
      "19579/19579 [==============================] - 0s 6us/step - loss: 0.9011 - acc: 0.6092\n",
      "Epoch 35/100\n",
      "19579/19579 [==============================] - 0s 6us/step - loss: 0.8987 - acc: 0.6075\n",
      "Epoch 36/100\n",
      "19579/19579 [==============================] - 0s 6us/step - loss: 0.8945 - acc: 0.6116\n",
      "Epoch 37/100\n",
      "19579/19579 [==============================] - 0s 6us/step - loss: 0.8911 - acc: 0.6182\n",
      "Epoch 38/100\n",
      "19579/19579 [==============================] - 0s 6us/step - loss: 0.8876 - acc: 0.6184\n",
      "Epoch 39/100\n",
      "19579/19579 [==============================] - 0s 6us/step - loss: 0.8866 - acc: 0.6227\n",
      "Epoch 40/100\n",
      "19579/19579 [==============================] - 0s 6us/step - loss: 0.8838 - acc: 0.6208\n",
      "Epoch 41/100\n",
      "19579/19579 [==============================] - 0s 6us/step - loss: 0.8793 - acc: 0.6273\n",
      "Epoch 42/100\n",
      "19579/19579 [==============================] - 0s 6us/step - loss: 0.8816 - acc: 0.6202\n",
      "Epoch 43/100\n",
      "19579/19579 [==============================] - 0s 6us/step - loss: 0.8795 - acc: 0.6212\n",
      "CPU times: user 6.2 s, sys: 179 ms, total: 6.38 s\n",
      "Wall time: 5.12 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6d95571cc0>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs=100\n",
    "# %time model.fit(X_combined, y_train_categorical, batch_size=16, epochs=epochs, callbacks=[keras.callbacks.EarlyStopping(patience=2, monitor='loss')])\n",
    "%time model.fit(X_combined, y_train_categorical, batch_size=256, epochs=epochs, callbacks=[keras.callbacks.EarlyStopping(patience=2, monitor='loss')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_15 (InputLayer)        (None, 158)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 3)                 477       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 477\n",
      "Trainable params: 477\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model(input_dim=X_combined.shape, fc1_dim=128)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "19579/19579 [==============================] - 0s 16us/step - loss: 4.3658 - acc: 0.3368\n",
      "Epoch 2/100\n",
      "19579/19579 [==============================] - 0s 6us/step - loss: 1.2495 - acc: 0.3549\n",
      "Epoch 3/100\n",
      "19579/19579 [==============================] - 0s 5us/step - loss: 1.1848 - acc: 0.3802\n",
      "Epoch 4/100\n",
      "19579/19579 [==============================] - 0s 5us/step - loss: 1.1320 - acc: 0.4078\n",
      "Epoch 5/100\n",
      "19579/19579 [==============================] - 0s 5us/step - loss: 1.0898 - acc: 0.4299\n",
      "Epoch 6/100\n",
      "19579/19579 [==============================] - 0s 6us/step - loss: 1.0591 - acc: 0.4484\n",
      "Epoch 7/100\n",
      "19579/19579 [==============================] - 0s 5us/step - loss: 1.0341 - acc: 0.4704\n",
      "Epoch 8/100\n",
      "19579/19579 [==============================] - 0s 6us/step - loss: 1.0138 - acc: 0.4896\n",
      "Epoch 9/100\n",
      "19579/19579 [==============================] - 0s 5us/step - loss: 0.9996 - acc: 0.5053\n",
      "Epoch 10/100\n",
      "19579/19579 [==============================] - 0s 5us/step - loss: 0.9891 - acc: 0.5167\n",
      "Epoch 11/100\n",
      "19579/19579 [==============================] - 0s 5us/step - loss: 0.9800 - acc: 0.5232\n",
      "Epoch 12/100\n",
      "19579/19579 [==============================] - 0s 5us/step - loss: 0.9736 - acc: 0.5294\n",
      "Epoch 13/100\n",
      "19579/19579 [==============================] - 0s 5us/step - loss: 0.9658 - acc: 0.5363\n",
      "Epoch 14/100\n",
      "19579/19579 [==============================] - 0s 6us/step - loss: 0.9618 - acc: 0.5437\n",
      "Epoch 15/100\n",
      "19579/19579 [==============================] - 0s 6us/step - loss: 0.9569 - acc: 0.5477\n",
      "Epoch 16/100\n",
      "19579/19579 [==============================] - 0s 5us/step - loss: 0.9512 - acc: 0.5531\n",
      "Epoch 17/100\n",
      "19579/19579 [==============================] - 0s 5us/step - loss: 0.9493 - acc: 0.5573\n",
      "Epoch 18/100\n",
      "19579/19579 [==============================] - 0s 5us/step - loss: 0.9439 - acc: 0.5624\n",
      "Epoch 19/100\n",
      "19579/19579 [==============================] - 0s 5us/step - loss: 0.9435 - acc: 0.5622\n",
      "Epoch 20/100\n",
      "19579/19579 [==============================] - 0s 5us/step - loss: 0.9368 - acc: 0.5719\n",
      "Epoch 21/100\n",
      "19579/19579 [==============================] - 0s 5us/step - loss: 0.9365 - acc: 0.5687\n",
      "Epoch 22/100\n",
      "19579/19579 [==============================] - 0s 5us/step - loss: 0.9298 - acc: 0.5769\n",
      "Epoch 23/100\n",
      "19579/19579 [==============================] - 0s 5us/step - loss: 0.9278 - acc: 0.5808\n",
      "Epoch 24/100\n",
      "19579/19579 [==============================] - 0s 5us/step - loss: 0.9238 - acc: 0.5855\n",
      "Epoch 25/100\n",
      "19579/19579 [==============================] - 0s 5us/step - loss: 0.9217 - acc: 0.5855\n",
      "Epoch 26/100\n",
      "19579/19579 [==============================] - 0s 5us/step - loss: 0.9161 - acc: 0.5985\n",
      "Epoch 27/100\n",
      "19579/19579 [==============================] - 0s 5us/step - loss: 0.9140 - acc: 0.5965\n",
      "Epoch 28/100\n",
      "19579/19579 [==============================] - 0s 5us/step - loss: 0.9114 - acc: 0.5978\n",
      "Epoch 29/100\n",
      "19579/19579 [==============================] - 0s 5us/step - loss: 0.9078 - acc: 0.6008\n",
      "Epoch 30/100\n",
      "19579/19579 [==============================] - 0s 5us/step - loss: 0.9075 - acc: 0.6004\n",
      "Epoch 31/100\n",
      "19579/19579 [==============================] - 0s 5us/step - loss: 0.9041 - acc: 0.6034\n",
      "Epoch 32/100\n",
      "19579/19579 [==============================] - 0s 5us/step - loss: 0.9033 - acc: 0.5989\n",
      "Epoch 33/100\n",
      "19579/19579 [==============================] - 0s 5us/step - loss: 0.9003 - acc: 0.6058\n",
      "Epoch 34/100\n",
      "19579/19579 [==============================] - 0s 5us/step - loss: 0.8953 - acc: 0.6145\n",
      "Epoch 35/100\n",
      "19579/19579 [==============================] - 0s 5us/step - loss: 0.8946 - acc: 0.6135\n",
      "Epoch 36/100\n",
      "19579/19579 [==============================] - 0s 5us/step - loss: 0.8904 - acc: 0.6197\n",
      "Epoch 37/100\n",
      "19579/19579 [==============================] - 0s 5us/step - loss: 0.8871 - acc: 0.6207\n",
      "Epoch 38/100\n",
      "19579/19579 [==============================] - 0s 5us/step - loss: 0.8853 - acc: 0.6226\n",
      "Epoch 39/100\n",
      "19579/19579 [==============================] - 0s 5us/step - loss: 0.8825 - acc: 0.6218\n",
      "Epoch 40/100\n",
      "19579/19579 [==============================] - 0s 5us/step - loss: 0.8812 - acc: 0.6240\n",
      "Epoch 41/100\n",
      "19579/19579 [==============================] - 0s 5us/step - loss: 0.8779 - acc: 0.6255\n",
      "Epoch 42/100\n",
      "19579/19579 [==============================] - 0s 5us/step - loss: 0.8755 - acc: 0.6287\n",
      "Epoch 43/100\n",
      "19579/19579 [==============================] - 0s 6us/step - loss: 0.8732 - acc: 0.6288\n",
      "Epoch 44/100\n",
      "19579/19579 [==============================] - 0s 5us/step - loss: 0.8721 - acc: 0.6335\n",
      "Epoch 45/100\n",
      "19579/19579 [==============================] - 0s 5us/step - loss: 0.8697 - acc: 0.6322\n",
      "Epoch 46/100\n",
      "19579/19579 [==============================] - 0s 5us/step - loss: 0.8663 - acc: 0.6358\n",
      "Epoch 47/100\n",
      "19579/19579 [==============================] - 0s 5us/step - loss: 0.8624 - acc: 0.6421\n",
      "Epoch 48/100\n",
      "19579/19579 [==============================] - 0s 5us/step - loss: 0.8622 - acc: 0.6408\n",
      "Epoch 49/100\n",
      "19579/19579 [==============================] - 0s 5us/step - loss: 0.8605 - acc: 0.6400\n",
      "Epoch 50/100\n",
      "19579/19579 [==============================] - 0s 5us/step - loss: 0.8594 - acc: 0.6387\n",
      "Epoch 51/100\n",
      "19579/19579 [==============================] - 0s 5us/step - loss: 0.8573 - acc: 0.6406\n",
      "Epoch 52/100\n",
      "19579/19579 [==============================] - 0s 5us/step - loss: 0.8562 - acc: 0.6429\n",
      "Epoch 53/100\n",
      "19579/19579 [==============================] - 0s 5us/step - loss: 0.8507 - acc: 0.6448\n",
      "Epoch 54/100\n",
      "19579/19579 [==============================] - 0s 6us/step - loss: 0.8519 - acc: 0.6436\n",
      "Epoch 55/100\n",
      "19579/19579 [==============================] - 0s 5us/step - loss: 0.8477 - acc: 0.6491\n",
      "Epoch 56/100\n",
      "19579/19579 [==============================] - 0s 5us/step - loss: 0.8455 - acc: 0.6470\n",
      "Epoch 57/100\n",
      "19579/19579 [==============================] - 0s 5us/step - loss: 0.8462 - acc: 0.6494\n",
      "Epoch 58/100\n",
      "19579/19579 [==============================] - 0s 5us/step - loss: 0.8441 - acc: 0.6534\n",
      "Epoch 59/100\n",
      "19579/19579 [==============================] - 0s 5us/step - loss: 0.8435 - acc: 0.6479\n",
      "Epoch 60/100\n",
      "19579/19579 [==============================] - 0s 5us/step - loss: 0.8415 - acc: 0.6509\n",
      "Epoch 61/100\n",
      "19579/19579 [==============================] - 0s 5us/step - loss: 0.8380 - acc: 0.6505\n",
      "Epoch 62/100\n",
      "19579/19579 [==============================] - 0s 5us/step - loss: 0.8391 - acc: 0.6494\n",
      "Epoch 63/100\n",
      "19579/19579 [==============================] - 0s 5us/step - loss: 0.8355 - acc: 0.6552\n",
      "Epoch 64/100\n",
      "19579/19579 [==============================] - 0s 5us/step - loss: 0.8322 - acc: 0.6600\n",
      "Epoch 65/100\n",
      "19579/19579 [==============================] - 0s 5us/step - loss: 0.8308 - acc: 0.6538\n",
      "Epoch 66/100\n",
      "19579/19579 [==============================] - 0s 5us/step - loss: 0.8292 - acc: 0.6584\n",
      "Epoch 67/100\n",
      "19579/19579 [==============================] - 0s 5us/step - loss: 0.8290 - acc: 0.6566\n",
      "Epoch 68/100\n",
      "19579/19579 [==============================] - 0s 5us/step - loss: 0.8258 - acc: 0.6581\n",
      "Epoch 69/100\n",
      "19579/19579 [==============================] - 0s 5us/step - loss: 0.8242 - acc: 0.6605\n",
      "Epoch 70/100\n",
      "19579/19579 [==============================] - 0s 5us/step - loss: 0.8238 - acc: 0.6620\n",
      "Epoch 71/100\n",
      "19579/19579 [==============================] - 0s 5us/step - loss: 0.8213 - acc: 0.6631\n",
      "Epoch 72/100\n",
      "19579/19579 [==============================] - 0s 5us/step - loss: 0.8198 - acc: 0.6640\n",
      "Epoch 73/100\n",
      "19579/19579 [==============================] - 0s 5us/step - loss: 0.8170 - acc: 0.6667\n",
      "Epoch 74/100\n",
      "19579/19579 [==============================] - 0s 5us/step - loss: 0.8156 - acc: 0.6662\n",
      "Epoch 75/100\n",
      "19579/19579 [==============================] - 0s 5us/step - loss: 0.8152 - acc: 0.6662\n",
      "Epoch 76/100\n",
      "19579/19579 [==============================] - 0s 5us/step - loss: 0.8137 - acc: 0.6681\n",
      "Epoch 77/100\n",
      "19579/19579 [==============================] - 0s 5us/step - loss: 0.8153 - acc: 0.6621\n",
      "Epoch 78/100\n",
      "19579/19579 [==============================] - 0s 5us/step - loss: 0.8134 - acc: 0.6647\n",
      "Epoch 79/100\n",
      "19579/19579 [==============================] - 0s 5us/step - loss: 0.8099 - acc: 0.6672\n",
      "Epoch 80/100\n",
      "19579/19579 [==============================] - 0s 5us/step - loss: 0.8075 - acc: 0.6703\n",
      "Epoch 81/100\n",
      "19579/19579 [==============================] - 0s 5us/step - loss: 0.8084 - acc: 0.6676\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19579/19579 [==============================] - 0s 5us/step - loss: 0.8060 - acc: 0.6697\n",
      "Epoch 83/100\n",
      "19579/19579 [==============================] - 0s 5us/step - loss: 0.8044 - acc: 0.6700\n",
      "Epoch 84/100\n",
      "19579/19579 [==============================] - 0s 5us/step - loss: 0.8054 - acc: 0.6692\n",
      "Epoch 85/100\n",
      "19579/19579 [==============================] - 0s 5us/step - loss: 0.8012 - acc: 0.6724\n",
      "Epoch 86/100\n",
      "19579/19579 [==============================] - 0s 5us/step - loss: 0.8025 - acc: 0.6701\n",
      "Epoch 87/100\n",
      "19579/19579 [==============================] - 0s 5us/step - loss: 0.8002 - acc: 0.6720\n",
      "Epoch 88/100\n",
      "19579/19579 [==============================] - 0s 5us/step - loss: 0.7977 - acc: 0.6749\n",
      "Epoch 89/100\n",
      "19579/19579 [==============================] - 0s 5us/step - loss: 0.7971 - acc: 0.6743\n",
      "Epoch 90/100\n",
      "19579/19579 [==============================] - 0s 5us/step - loss: 0.7985 - acc: 0.6701\n",
      "Epoch 91/100\n",
      "19579/19579 [==============================] - 0s 5us/step - loss: 0.7951 - acc: 0.6738\n",
      "Epoch 92/100\n",
      "19579/19579 [==============================] - 0s 5us/step - loss: 0.7942 - acc: 0.6750\n",
      "Epoch 93/100\n",
      "19579/19579 [==============================] - 0s 5us/step - loss: 0.7918 - acc: 0.6766\n",
      "Epoch 94/100\n",
      "19579/19579 [==============================] - 0s 5us/step - loss: 0.7913 - acc: 0.6741\n",
      "Epoch 95/100\n",
      "19579/19579 [==============================] - 0s 5us/step - loss: 0.7887 - acc: 0.6781\n",
      "Epoch 96/100\n",
      "19579/19579 [==============================] - 0s 5us/step - loss: 0.7891 - acc: 0.6783\n",
      "Epoch 97/100\n",
      "19579/19579 [==============================] - 0s 5us/step - loss: 0.7890 - acc: 0.6798\n",
      "CPU times: user 13.4 s, sys: 331 ms, total: 13.7 s\n",
      "Wall time: 10.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6d95276c18>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs=100\n",
    "# %time model.fit(X_combined, y_train_categorical, batch_size=16, epochs=epochs, callbacks=[keras.callbacks.EarlyStopping(patience=2, monitor='loss')])\n",
    "%time model.fit(X_combined, y_train_categorical, batch_size=256, epochs=epochs, callbacks=[keras.callbacks.EarlyStopping(patience=2, monitor='loss')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Increase Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_17 (InputLayer)        (None, 158)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 64)                10176     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 3)                 195       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 10,371\n",
      "Trainable params: 10,371\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "19579/19579 [==============================] - 0s 22us/step - loss: 2.0919 - acc: 0.3352\n",
      "Epoch 2/100\n",
      "19579/19579 [==============================] - 0s 8us/step - loss: 1.0618 - acc: 0.4563\n",
      "Epoch 3/100\n",
      "19579/19579 [==============================] - 0s 8us/step - loss: 1.0072 - acc: 0.5077\n",
      "Epoch 4/100\n",
      "19579/19579 [==============================] - 0s 7us/step - loss: 0.9646 - acc: 0.5457\n",
      "Epoch 5/100\n",
      "19579/19579 [==============================] - 0s 7us/step - loss: 0.9445 - acc: 0.5633\n",
      "Epoch 6/100\n",
      "19579/19579 [==============================] - 0s 7us/step - loss: 0.9201 - acc: 0.5789\n",
      "Epoch 7/100\n",
      "19579/19579 [==============================] - 0s 7us/step - loss: 0.9136 - acc: 0.5859\n",
      "Epoch 8/100\n",
      "19579/19579 [==============================] - 0s 8us/step - loss: 0.8941 - acc: 0.6023\n",
      "Epoch 9/100\n",
      "19579/19579 [==============================] - 0s 8us/step - loss: 0.8824 - acc: 0.6146\n",
      "Epoch 10/100\n",
      "19579/19579 [==============================] - 0s 8us/step - loss: 0.8582 - acc: 0.6339\n",
      "Epoch 11/100\n",
      "19579/19579 [==============================] - 0s 7us/step - loss: 0.8693 - acc: 0.6136\n",
      "Epoch 12/100\n",
      "19579/19579 [==============================] - 0s 8us/step - loss: 0.8443 - acc: 0.6397\n",
      "Epoch 13/100\n",
      "19579/19579 [==============================] - 0s 7us/step - loss: 0.8405 - acc: 0.6388\n",
      "Epoch 14/100\n",
      "19579/19579 [==============================] - 0s 7us/step - loss: 0.8227 - acc: 0.6486\n",
      "Epoch 15/100\n",
      "19579/19579 [==============================] - 0s 8us/step - loss: 0.8089 - acc: 0.6572\n",
      "Epoch 16/100\n",
      "19579/19579 [==============================] - 0s 8us/step - loss: 0.7999 - acc: 0.6658\n",
      "Epoch 17/100\n",
      "19579/19579 [==============================] - 0s 7us/step - loss: 0.8009 - acc: 0.6579\n",
      "Epoch 18/100\n",
      "19579/19579 [==============================] - 0s 7us/step - loss: 0.7976 - acc: 0.6583\n",
      "Epoch 19/100\n",
      "19579/19579 [==============================] - 0s 7us/step - loss: 0.7929 - acc: 0.6605\n",
      "Epoch 20/100\n",
      "19579/19579 [==============================] - 0s 8us/step - loss: 0.7721 - acc: 0.6755\n",
      "Epoch 21/100\n",
      "19579/19579 [==============================] - 0s 8us/step - loss: 0.7965 - acc: 0.6547\n",
      "Epoch 22/100\n",
      "19579/19579 [==============================] - 0s 8us/step - loss: 0.7784 - acc: 0.6645\n",
      "CPU times: user 4.85 s, sys: 175 ms, total: 5.03 s\n",
      "Wall time: 3.86 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6d94f8e4a8>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_model(input_dim, fc1_dim, fc2_dim, output_dim=3, lr=1e-3):\n",
    "    inputs = keras.layers.Input(input_dim[1:])\n",
    "    \n",
    "    x_fc1 = keras.layers.Dense(fc2_dim)(inputs)\n",
    "    x_fc2 = keras.layers.Dense(output_dim)(x_fc1)\n",
    "    outputs = keras.layers.Activation('softmax')(x_fc2)\n",
    "    \n",
    "    model = keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "    optimizer = keras.optimizers.Adam(lr=lr)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                 optimizer=optimizer,\n",
    "                 metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "model = create_model(input_dim=X_combined.shape, fc1_dim=128, fc2_dim=64)\n",
    "model.summary()\n",
    "\n",
    "epochs=100\n",
    "%time model.fit(X_combined, y_train_categorical, batch_size=256, epochs=epochs, callbacks=[keras.callbacks.EarlyStopping(patience=2, monitor='loss')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
